{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aead1d5-c451-49ff-b38c-36db2464a4bf",
   "metadata": {},
   "source": [
    "# Entrenamiento de un Agente PPO con VizDoom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1f8599-8d25-4c38-988a-94488313faef",
   "metadata": {},
   "source": [
    "En este notebook, implementaremos un agente de Reinforcement Learning usando el algoritmo Proximal Policy Optimization (PPO) para jugar al juego de VizDoom.\n",
    "Trabajo realizado por:\n",
    "* Damián Pramparo\n",
    "* Federico Domínguez Gómez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b3296c-6714-40cb-aebb-7fe4d6c24a30",
   "metadata": {},
   "source": [
    "## Importación de bibliotecas\n",
    "Usaremos las siguientes bibliotecas:\n",
    "* **vizdoom**: Librería para interactuar con el entorno de VizDoom.\n",
    "* **pandas**: Usada para crear un DataFrame y guardar datos en un archivo CSV.\n",
    "* **torch**: Biblioteca para el aprendizaje profundo con PyTorch.\n",
    "* **numpy**: Usada para manipular matrices numéricas.\n",
    "* **Pool**: Para poder entrenas varios agentes al mismo tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a666dcdb-f3d3-4f8f-98c1-ea5fd29d57a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vizdoom\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b8a862-0722-4476-a986-af6db3e0c425",
   "metadata": {},
   "source": [
    "# Definición de la clase PPOAgent\n",
    "Creamos una clase **PPOAgent** que representa nuestro agente PPO. Esta clase se encarga de definir la arquitectura de la política y de implementar los métodos necesarios para el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d65d1d2-e59f-4e5e-bbdc-46ab5060ddb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PPOAgent:\n",
    "    def __init__(self, state_dim, action_dim, learning_rate=0.001, alpha=0.99, epsilon=0.1):\n",
    "        self.policy_net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(state_dim, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(128, action_dim),\n",
    "        )\n",
    "\n",
    "        self.optimizer = torch.optim.RMSprop(self.policy_net.parameters(), lr=learning_rate, alpha=alpha, eps=epsilon)\n",
    "        \n",
    "    def policy(self, state):\n",
    "        logits = self.policy_net(state)\n",
    "\n",
    "        logits = torch.squeeze(logits)\n",
    "\n",
    "        action_probs = torch.softmax(logits, dim=0)\n",
    "        action = torch.multinomial(action_probs, 1).item()\n",
    "\n",
    "        return action\n",
    "\n",
    "    def learn(self, experiences):\n",
    "        loss = self.ppo_loss(experiences)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def ppo_loss(self, experiences):\n",
    "        log_probs = [experience['log_probs'] for experience in experiences]\n",
    "        advantages = [experience['advantage'] for experience in experiences]\n",
    "        \n",
    "        log_probs_tensor = torch.tensor(log_probs, requires_grad=True)\n",
    "        advantages_tensor = torch.tensor(advantages, requires_grad=True)    \n",
    "\n",
    "        ## Agrego una dimension adicional sino da error \n",
    "        log_probs_tensor = log_probs_tensor.unsqueeze(1)  \n",
    "        advantages_tensor = advantages_tensor.unsqueeze(1) \n",
    "\n",
    "        policy_loss = -torch.mean(torch.sum(log_probs_tensor * advantages_tensor, dim=1))\n",
    "\n",
    "        return policy_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb6bfd96-aae1-4a8a-8839-f6e29bfbaeac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_actions = [\n",
    "    [1, 0, 0, 0, 0, 0, 0],  # MOVE_LEFT\n",
    "    [0, 1, 0, 0, 0, 0, 0],  # MOVE_RIGHT\n",
    "    [0, 0, 1, 0, 0, 0, 0],  # ATTACK\n",
    "    [0, 0, 0, 1, 0, 0, 0],  # MOVE_FORWARD\n",
    "    [0, 0, 0, 0, 1, 0, 0],  # MOVE_BACKWARD\n",
    "    [0, 0, 0, 0, 0, 1, 0],  # TURN_LEFT\n",
    "    [0, 0, 0, 0, 0, 0, 1],  # TURN_RIGHT\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d7c108a-96e5-448d-8b57-a5d8623e358f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_agent(agent_id, learning_rate, alpha, epsilon, sample_actions):\n",
    "    state_dim = 4\n",
    "    action_dim = 7\n",
    "    num_episodes = 100\n",
    "    \n",
    "    agent = PPOAgent(state_dim, action_dim, learning_rate, alpha, epsilon)\n",
    "    \n",
    "    game = vizdoom.DoomGame()\n",
    "    game.load_config(\"deadly_corridor.cfg\")\n",
    "    game.set_doom_scenario_path(\"deadly_corridor.wad\")\n",
    "    game.init()\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        game.new_episode()\n",
    "\n",
    "        state = torch.from_numpy(np.zeros((4,))).float() \n",
    "\n",
    "        experiences = []\n",
    "        while not game.is_episode_finished():\n",
    "            action = agent.policy(state)\n",
    "\n",
    "            game.make_action(sample_actions[action])\n",
    "\n",
    "            next_state = torch.from_numpy(np.zeros((4,))).float()\n",
    "            reward = game.get_last_reward()\n",
    "    \n",
    "            advantage = reward \n",
    "\n",
    "            log_prob = torch.log(agent.policy_net(state)[action])\n",
    "\n",
    "            experiences.append({\n",
    "                'state': state,\n",
    "                'action': action,\n",
    "                'reward': reward,\n",
    "                'next_state': next_state,\n",
    "                'advantage': advantage,\n",
    "                'log_probs': log_prob\n",
    "            })\n",
    "        \n",
    "            state = next_state\n",
    "\n",
    "        agent.learn(experiences)\n",
    "        df = pd.DataFrame(experiences)\n",
    "        df.to_csv('datos.csv')\n",
    "        print('Episode {}: {}'.format(episode, game.get_total_reward()))\n",
    "\n",
    "    game.close()\n",
    "    return agent_id, agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3958021c-f66b-4c07-8abb-607d2d120bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: -103.22137451171875Episode 0: -103.23233032226562\n",
      "\n",
      "Episode 0: -107.21281433105469\n",
      "Episode 0: -114.01736450195312\n",
      "Episode 1: -113.34738159179688\n",
      "Episode 1: -99.25469970703125\n",
      "Episode 1: -115.98941040039062\n",
      "Episode 2: -103.3702392578125\n",
      "Episode 1: -101.48481750488281\n",
      "Episode 3: -112.37275695800781\n",
      "Episode 4: -115.9073486328125\n",
      "Episode 2: -112.25404357910156Episode 2: -110.64141845703125\n",
      "\n",
      "Episode 2: -100.48384094238281\n",
      "Episode 5: -113.77871704101562\n",
      "Episode 6: -115.99784851074219\n",
      "Episode 3: -105.92947387695312\n",
      "Episode 3: -98.95620727539062\n",
      "Episode 7: -115.99856567382812\n",
      "Episode 8: -109.82630920410156\n",
      "Episode 4: -112.47196960449219\n",
      "Episode 9: -115.9708251953125\n",
      "Episode 3: -79.02413940429688\n",
      "Episode 10: -105.54454040527344Episode 4: -101.91645812988281\n",
      "\n",
      "Episode 4: -78.50425720214844Episode 11: -83.68807983398438\n",
      "\n",
      "Episode 5: -92.35569763183594\n",
      "Episode 5: -102.18661499023438\n",
      "Episode 12: -82.40225219726562\n",
      "Episode 5: -113.17874145507812Episode 13: -114.45501708984375\n",
      "\n",
      "Episode 14: -108.89413452148438\n",
      "Episode 6: -111.73545837402344\n",
      "Episode 6: -101.75895690917969\n",
      "Episode 6: -90.94148254394531\n",
      "Episode 15: -102.80462646484375\n",
      "Episode 7: -98.20783996582031\n",
      "Episode 16: -106.10893249511719Episode 7: -79.93327331542969\n",
      "\n",
      "Episode 7: -108.06587219238281\n",
      "Episode 8: -101.18809509277344\n",
      "Episode 17: -115.31912231445312\n",
      "Episode 8: -106.06427001953125Episode 18: -115.67596435546875Episode 8: -101.82888793945312\n",
      "\n",
      "\n",
      "Episode 9: -109.45039367675781\n",
      "Episode 9: -113.43144226074219\n",
      "Episode 19: -51.566192626953125\n",
      "Episode 9: -111.51919555664062\n",
      "Episode 20: -86.00344848632812\n",
      "Episode 10: -111.62583923339844\n",
      "Episode 21: -115.78781127929688Episode 10: -102.51835632324219\n",
      "\n",
      "Episode 22: -114.32745361328125\n",
      "Episode 23: -115.97563171386719\n",
      "Episode 11: -104.38836669921875\n",
      "Episode 11: -98.97627258300781\n",
      "Episode 12: -112.7772216796875Episode 24: -115.33212280273438\n",
      "\n",
      "Episode 25: -103.76580810546875\n",
      "Episode 12: -109.00028991699219\n",
      "Episode 10: -22.43780517578125\n",
      "Episode 26: -104.94827270507812\n",
      "Episode 27: -96.61878967285156\n",
      "Episode 13: -102.15402221679688\n",
      "Episode 11: -87.75868225097656\n",
      "Episode 13: -94.313720703125\n",
      "Episode 28: -59.62644958496094Episode 12: -101.00810241699219\n",
      "\n",
      "Episode 14: -94.86836242675781Episode 13: -109.66299438476562\n",
      "\n",
      "Episode 29: -87.60794067382812\n",
      "Episode 14: -112.77861022949219\n",
      "Episode 15: -114.87921142578125\n",
      "Episode 30: -112.11180114746094\n",
      "Episode 14: -88.1107177734375\n",
      "Episode 16: -115.97549438476562\n",
      "Episode 31: -76.99734497070312\n",
      "Episode 15: -115.98959350585938\n",
      "Episode 17: -103.95332336425781\n",
      "Episode 15: -81.41119384765625\n",
      "Episode 32: -115.27871704101562\n",
      "Episode 16: -100.84634399414062\n",
      "Episode 33: -114.56837463378906\n",
      "Episode 18: -111.43179321289062\n",
      "Episode 17: -72.94270324707031\n",
      "Episode 16: -80.17364501953125\n",
      "Episode 34: -111.07951354980469\n",
      "Episode 19: -110.36674499511719Episode 18: -108.66697692871094\n",
      "\n",
      "Episode 17: -104.99618530273438\n",
      "Episode 20: -108.64683532714844Episode 19: -115.97372436523438\n",
      "\n",
      "Episode 18: -115.80458068847656\n",
      "Episode 21: -110.23930358886719\n",
      "Episode 22: -111.60223388671875\n",
      "Episode 23: -111.85997009277344\n",
      "Episode 20: -106.98222351074219\n",
      "Episode 24: -115.87838745117188\n",
      "Episode 25: -93.64744567871094\n",
      "Episode 26: -115.84609985351562\n",
      "Episode 35: -35.27880859375\n",
      "Episode 21: -81.86724853515625\n",
      "Episode 27: -101.92335510253906\n",
      "Episode 28: -113.17572021484375Episode 19: -69.48165893554688\n",
      "\n",
      "Episode 36: -115.99227905273438\n",
      "Episode 29: -101.13581848144531\n",
      "Episode 30: -108.56199645996094\n",
      "Episode 37: -106.42942810058594\n",
      "Episode 20: -115.97343444824219\n",
      "Episode 31: -96.250244140625Episode 22: -94.90171813964844\n",
      "\n",
      "Episode 32: -115.99293518066406\n",
      "Episode 33: -110.74517822265625\n",
      "Episode 23: -115.52958679199219Episode 21: -95.96763610839844\n",
      "Episode 38: -105.58712768554688\n",
      "\n",
      "Episode 24: -96.95130920410156Episode 34: -62.6119384765625\n",
      "\n",
      "Episode 35: -114.57289123535156\n",
      "Episode 39: -114.218017578125\n",
      "Episode 36: -113.64559936523438\n",
      "Episode 40: -86.88114929199219\n",
      "Episode 22: -42.83624267578125Episode 37: -98.66921997070312\n",
      "Episode 25: -88.98995971679688\n",
      "\n",
      "Episode 41: -115.9755859375\n",
      "Episode 23: -112.40533447265625\n",
      "Episode 42: -115.062255859375\n",
      "Episode 26: -100.07965087890625\n",
      "Episode 38: -82.67488098144531\n",
      "Episode 39: -102.49752807617188\n",
      "Episode 43: -115.99293518066406\n",
      "Episode 24: -92.53515625\n",
      "Episode 27: -97.64949035644531\n",
      "Episode 40: -68.68708801269531\n",
      "Episode 41: -113.68124389648438\n",
      "Episode 25: -113.30790710449219\n",
      "Episode 44: -78.84454345703125\n",
      "Episode 26: -111.38534545898438Episode 45: -106.21304321289062\n",
      "\n",
      "Episode 28: -68.67747497558594\n",
      "Episode 29: -97.36257934570312\n",
      "Episode 42: -74.01103210449219\n",
      "Episode 43: -115.97125244140625\n",
      "Episode 27: -56.48736572265625\n",
      "Episode 30: -89.02479553222656\n",
      "Episode 46: -100.48823547363281\n",
      "Episode 31: -74.89764404296875\n",
      "Episode 47: -112.49349975585938\n",
      "Episode 28: -115.97566223144531\n",
      "Episode 44: -111.05317687988281\n",
      "Episode 32: -69.8072509765625\n",
      "Episode 48: -98.01174926757812\n",
      "Episode 33: -114.66328430175781\n",
      "Episode 45: -105.32786560058594\n",
      "Episode 34: -98.09623718261719Episode 49: -108.10716247558594\n",
      "\n",
      "Episode 29: -54.97557067871094\n",
      "Episode 46: -93.63481140136719\n",
      "Episode 47: -115.99453735351562\n",
      "Episode 30: -81.94096374511719\n",
      "Episode 35: -62.0047607421875\n",
      "Episode 48: -115.96478271484375\n",
      "Episode 36: -114.78521728515625\n",
      "Episode 31: -115.74006652832031\n",
      "Episode 50: -69.6790771484375\n",
      "Episode 32: -102.463134765625\n",
      "Episode 37: -72.93937683105469\n",
      "Episode 33: -115.99501037597656\n",
      "Episode 49: -83.5848388671875Episode 51: -99.97508239746094\n",
      "\n",
      "Episode 38: -115.98832702636719\n",
      "Episode 39: -115.78831481933594\n",
      "Episode 52: -99.57872009277344\n",
      "Episode 34: -115.99363708496094\n",
      "Episode 40: -95.6156005859375\n",
      "Episode 50: -114.47781372070312\n",
      "Episode 41: -103.04623413085938\n",
      "Episode 51: -115.97869873046875Episode 53: -79.98944091796875\n",
      "\n",
      "Episode 42: -106.38858032226562\n",
      "Episode 43: -112.709228515625\n",
      "Episode 54: -115.9052734375\n",
      "Episode 35: -90.64964294433594\n",
      "Episode 55: -113.3536376953125Episode 44: -87.64834594726562\n",
      "\n",
      "Episode 52: -115.99784851074219\n",
      "Episode 36: -105.49464416503906\n",
      "Episode 45: -115.97869873046875\n",
      "Episode 46: -114.96737670898438\n",
      "Episode 53: -60.69700622558594\n",
      "Episode 37: -112.66537475585938Episode 56: -115.97563171386719\n",
      "\n",
      "Episode 47: -99.13920593261719\n",
      "Episode 54: -86.78598022460938\n",
      "Episode 48: -95.12336730957031\n",
      "Episode 49: -86.41085815429688\n",
      "Episode 38: -99.73619079589844\n",
      "Episode 57: -82.05970764160156\n",
      "Episode 55: -105.25323486328125\n",
      "Episode 58: -98.97000122070312\n",
      "Episode 50: -40.322357177734375\n",
      "Episode 39: -93.72569274902344\n",
      "Episode 51: -72.6571044921875\n",
      "Episode 56: -114.37945556640625\n",
      "Episode 40: -111.51679992675781\n",
      "Episode 41: -94.30503845214844Episode 57: -115.89207458496094\n",
      "\n",
      "Episode 52: -18.610809326171875\n",
      "Episode 53: -102.90597534179688\n",
      "Episode 59: -87.96165466308594\n",
      "Episode 54: -99.55076599121094\n",
      "Episode 55: -95.44564819335938\n",
      "Episode 60: -109.27497863769531\n",
      "Episode 42: -103.42555236816406\n",
      "Episode 56: -115.00758361816406\n",
      "Episode 58: -62.91358947753906\n",
      "Episode 57: -110.69461059570312\n",
      "Episode 43: -99.400146484375Episode 61: -105.73735046386719\n",
      "\n",
      "Episode 58: -104.45973205566406\n",
      "Episode 59: -101.71829223632812\n",
      "Episode 59: -85.34881591796875\n",
      "Episode 44: -94.25689697265625\n",
      "Episode 60: -96.07998657226562\n",
      "Episode 60: -114.33554077148438\n",
      "Episode 61: -111.77738952636719\n",
      "Episode 62: -32.937408447265625\n",
      "Episode 45: -38.15269470214844\n",
      "Episode 63: -111.89631652832031\n",
      "Episode 62: -102.30941772460938\n",
      "Episode 64: -97.41230773925781\n",
      "Episode 46: -98.98927307128906\n",
      "Episode 61: -115.97865295410156\n",
      "Episode 63: -77.96014404296875\n",
      "Episode 47: -83.46759033203125Episode 64: -105.86599731445312\n",
      "\n",
      "Episode 65: -87.41256713867188\n",
      "Episode 62: -104.28788757324219\n",
      "Episode 65: -99.3470458984375\n",
      "Episode 48: -115.97666931152344\n",
      "Episode 66: -109.01548767089844\n",
      "Episode 63: -105.9901123046875\n",
      "Episode 66: -105.06367492675781\n",
      "Episode 67: -80.14151000976562\n",
      "Episode 64: -99.50717163085938\n",
      "Episode 49: -72.21339416503906\n",
      "Episode 67: -115.92964172363281\n",
      "Episode 68: -78.94059753417969\n",
      "Episode 69: -99.68429565429688\n",
      "Episode 68: -95.15345764160156\n",
      "Episode 70: -68.18778991699219Episode 65: -108.64888000488281\n",
      "\n",
      "Episode 50: -78.24244689941406\n",
      "Episode 66: -105.4110107421875\n",
      "Episode 71: -115.94610595703125\n",
      "Episode 69: -98.39936828613281\n",
      "Episode 72: -114.5382080078125\n",
      "Episode 73: -112.98477172851562Episode 67: -115.93183898925781\n",
      "\n",
      "Episode 74: -86.020751953125\n",
      "Episode 68: -84.38423156738281\n",
      "Episode 75: -113.04522705078125\n",
      "Episode 51: 10.147354125976562\n",
      "Episode 70: -109.9381103515625\n",
      "Episode 76: -110.56349182128906\n",
      "Episode 69: -113.63444519042969\n",
      "Episode 77: -111.7442626953125\n",
      "Episode 71: -106.9635009765625\n",
      "Episode 70: -103.16766357421875Episode 78: -115.13290405273438\n",
      "\n",
      "Episode 52: -100.23445129394531\n",
      "Episode 79: -109.41897583007812\n",
      "Episode 72: -98.7655029296875Episode 71: -109.0186767578125\n",
      "\n",
      "Episode 53: -96.64112854003906\n",
      "Episode 73: -98.28158569335938\n",
      "Episode 80: -72.29978942871094\n",
      "Episode 74: -115.94197082519531\n",
      "Episode 54: -105.64097595214844\n",
      "Episode 72: -65.75772094726562\n",
      "Episode 73: -112.2552490234375Episode 75: -79.02752685546875Episode 55: -108.22261047363281\n",
      "\n",
      "\n",
      "Episode 81: -56.71217346191406\n",
      "Episode 82: -115.91127014160156\n",
      "Episode 74: -108.72006225585938\n",
      "Episode 76: -95.18843078613281\n",
      "Episode 56: -115.88893127441406Episode 83: -89.0406494140625\n",
      "\n",
      "Episode 75: -100.45648193359375Episode 84: -92.60531616210938\n",
      "\n",
      "Episode 77: -113.11790466308594\n",
      "Episode 57: -95.465576171875Episode 85: -114.87838745117188\n",
      "\n",
      "Episode 76: -115.99784851074219Episode 86: -113.91122436523438\n",
      "\n",
      "Episode 78: -110.69142150878906\n",
      "Episode 87: -95.4415283203125\n",
      "Episode 77: -102.44999694824219\n",
      "Episode 79: -114.36654663085938\n",
      "Episode 58: -73.89523315429688Episode 80: -115.85520935058594\n",
      "\n",
      "Episode 78: -99.57598876953125\n",
      "Episode 88: -65.23309326171875\n",
      "Episode 79: -112.75920104980469\n",
      "Episode 89: -106.75616455078125\n",
      "Episode 90: -104.59703063964844\n",
      "Episode 80: -70.50942993164062\n",
      "Episode 91: -115.91644287109375\n",
      "Episode 81: -105.5965576171875\n",
      "Episode 92: -113.6357421875\n",
      "Episode 81: -107.9169921875\n",
      "Episode 93: -88.13107299804688\n",
      "Episode 59: -10.840164184570312\n",
      "Episode 82: -115.99931335449219\n",
      "Episode 82: -89.66583251953125\n",
      "Episode 94: -54.77534484863281\n",
      "Episode 60: -113.82534790039062\n",
      "Episode 95: -115.4359130859375\n",
      "Episode 83: -112.84776306152344\n",
      "Episode 83: -115.97587585449219\n",
      "Episode 96: -98.2615966796875\n",
      "Episode 61: -100.63973999023438\n",
      "Episode 84: -115.1412353515625Episode 84: -113.24766540527344\n",
      "\n",
      "Episode 97: -18.612350463867188\n",
      "Episode 98: -61.85612487792969\n",
      "Episode 99: -110.38311767578125\n",
      "Episode 85: -91.18559265136719\n",
      "Episode 85: -90.17878723144531\n",
      "Episode 86: -110.47811889648438\n",
      "Episode 62: -47.68147277832031Episode 87: -108.75213623046875\n",
      "\n",
      "Episode 86: -111.880859375\n",
      "Episode 63: -80.0836181640625\n",
      "Episode 88: -101.38581848144531\n",
      "Episode 89: -97.40005493164062\n",
      "Episode 87: -113.05854797363281\n",
      "Episode 64: -95.44137573242188\n",
      "Episode 90: -115.99293518066406\n",
      "Episode 65: -115.91839599609375\n",
      "Episode 88: -56.46504211425781\n",
      "Episode 91: -111.02647399902344\n",
      "Episode 92: -98.83392333984375\n",
      "Episode 66: -50.57899475097656\n",
      "Episode 93: -101.95132446289062\n",
      "Episode 94: -102.18290710449219\n",
      "Episode 89: -38.64894104003906\n",
      "Episode 67: -108.72134399414062\n",
      "Episode 68: -115.83888244628906\n",
      "Episode 90: -104.69068908691406\n",
      "Episode 69: -111.65025329589844\n",
      "Episode 95: -76.52342224121094\n",
      "Episode 91: -115.20808410644531\n",
      "Episode 92: -92.92147827148438Episode 96: -93.78587341308594\n",
      "\n",
      "Episode 70: -95.576416015625\n",
      "Episode 93: -113.0621337890625\n",
      "Episode 97: -77.03083801269531\n",
      "Episode 94: -100.32872009277344\n",
      "Episode 98: -95.7281494140625\n",
      "Episode 95: -112.34733581542969\n",
      "Episode 99: -87.81556701660156\n",
      "Episode 71: -97.67671203613281\n",
      "Episode 96: -115.39230346679688\n",
      "Episode 72: -81.10980224609375\n",
      "Episode 97: -98.17880249023438\n",
      "Episode 73: -100.36152648925781\n",
      "Episode 98: -97.69013977050781\n",
      "Episode 74: -105.62355041503906\n",
      "Episode 99: -53.11659240722656\n",
      "Episode 75: -115.45265197753906\n",
      "Episode 76: -70.06266784667969\n",
      "Episode 77: -101.59355163574219\n",
      "Episode 78: -85.71774291992188\n",
      "Episode 79: -115.99862670898438\n",
      "Episode 80: -103.3896484375\n",
      "Episode 81: -100.41156005859375\n",
      "Episode 82: -93.69947814941406\n",
      "Episode 83: -109.10946655273438\n",
      "Episode 84: -115.97616577148438\n",
      "Episode 85: -87.18644714355469\n",
      "Episode 86: -37.38697814941406\n",
      "Episode 87: -108.13490295410156\n",
      "Episode 88: -89.67007446289062\n",
      "Episode 89: -49.16539001464844\n",
      "Episode 90: -115.81779479980469\n",
      "Episode 91: -110.01654052734375\n",
      "Episode 92: -107.03634643554688\n",
      "Episode 93: -38.65232849121094\n",
      "Episode 94: -94.39898681640625\n",
      "Episode 95: -76.15776062011719\n",
      "Episode 96: -95.45863342285156\n",
      "Episode 97: -97.53178405761719\n",
      "Episode 98: -114.40007019042969\n",
      "Episode 99: -73.51980590820312\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Definimos las combinaciones de hiperparámetros a probar\n",
    "    hyperparameter_combinations = [\n",
    "        (0, 0.001, 0.99, 0.1),\n",
    "        (1, 0.001, 0.95, 0.2),\n",
    "        (2, 0.0005, 0.99, 0.05),\n",
    "        (3, 0.002, 0.98, 0.15)\n",
    "    ]\n",
    "    \n",
    "    # Creamos una piscina de procesos para entrenar a los agentes en paralelo\n",
    "    with Pool(4) as pool:\n",
    "        results = pool.starmap(train_agent, [(agent_id, lr, a, eps, sample_actions) for agent_id, lr, a, eps in hyperparameter_combinations])\n",
    "\n",
    "    # Procesamos los resultados\n",
    "    trained_agents = {agent_id: agent for agent_id, agent in results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a928e0-f69e-40fc-9521-44ba7c0a7857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#no funciona, y no tengo idea por qué ni como hacer que ande\n",
    "# Definimos una función para evaluar a un agente en el entorno\n",
    "def evaluate_agent(agent, game, sample_actions, num_evaluation_episodes):\n",
    "    total_rewards = []\n",
    "    \n",
    "    for episode in range(num_evaluation_episodes):\n",
    "        game.new_episode()\n",
    "        state = torch.from_numpy(np.zeros((4,))).float()\n",
    "        episode_reward = 0\n",
    "        \n",
    "        while not game.is_episode_finished():\n",
    "            action = agent.policy(state)\n",
    "            game.make_action(sample_actions[action])\n",
    "            next_state = torch.from_numpy(np.zeros((4,))).float()\n",
    "            episode_reward += game.get_last_reward()\n",
    "            state = next_state\n",
    "        \n",
    "        total_rewards.append(episode_reward)\n",
    "    \n",
    "    average_reward = np.mean(total_rewards)\n",
    "    return average_reward\n",
    "\n",
    "best_agent_id = None\n",
    "best_average_reward = float(\"-inf\")\n",
    "\n",
    "evaluation_results = {}\n",
    "\n",
    "for agent_id, learning_rate, alpha, epsilon in hyperparameter_combinations:\n",
    "    print(f\"Evaluando Agente {agent_id} con hiperparámetros: lr={learning_rate}, alpha={alpha}, epsilon={epsilon}\")\n",
    "    \n",
    "    trained_agent = train_agent(agent_id, learning_rate, alpha, epsilon, sample_actions)\n",
    "    \n",
    "    average_reward = evaluate_agent(trained_agent, game, sample_actions, num_evaluation_episodes)\n",
    "print(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1256ce15-d8bb-4b10-91ad-1054815a1f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd0289-253c-4a13-a454-4cce15f6f2da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
